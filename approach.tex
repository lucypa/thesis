\chapter{Approach}\label{ch:approach}
To achieve high performance I/O on seL4, this thesis will extend the current seL4 Device Driver Framework prototype 
to securely support multiple client applications on a multicore system. While doing so, 
we will evaluate the sDDF design while improving any bottlenecks in the current implementation
and optimise the system for large scale, high throughput networking systems.

\section{Design Goals}
When extending the sDDF, we wish to maintain the current prototype's design goals. 
Specifically, these are:
\begin{itemize}
\item \textbf{Radical Simplicity}: Each component in the framework should be kept as simple as possible. While verification is outside the scope
of this thesis, keeping each component simple will aid any future verification effort while assisting developers to reason about it.
\item \textbf{Strict separation of concerns}: Each component has one and only one job to do. 
\item \textbf{Swappable policy}: Any policy enforced by the framework should be swappable for another policy for different use cases.
This enables the framework to be flexible and support different use cases while keeping the implementation simple.
\item \textbf{Secure}: The framework should be secure by taking advantage of the security properties provided by seL4. seL4 guarantees
complete isolation of user-level components, and its capability system provides fine grained access control. This motivates the framework to apply
the principle of least authority: components \emph{only} have the minimum capabilities required to perform their job. Clients must not be able
to interfere with one another. 
\item \textbf{Performance}: The solution should be performance competitive with the current prototype (see \autoref{ch:sddf}),
as well as with other existing I/O frameworks (see \autoref{ch:related_work}).
\end{itemize}

\section{Methodology}
To accomplish our goal, we need to:
\begin{enumerate}
    \item Implement policies for the multiplexers, \autoref{s:mux_pol}
    \item Support broadcast protocols, \autoref{s:arp}
    \item Implement different client applications that imitate different use cases, \autoref{s:client}
    \item Add a second client to the prototype for testing, \autoref{s:client2}
    \item Support execution across multiple CPUs, \autoref{s:multicore}
    \item Perform a threat analysis of the framework to outline, and where possible, improve any
         security vulnerabilities in our design, \autoref{s:security}
    \item Evaluate and optimise: evaluate the solution by benchmarking the system throughout development 
    and improve any performance bottlenecks.
\end{enumerate}

\subsection{Multiplexer Policies} \label{s:mux_pol}
The current implementation is configured for a single client application. As such, neither the receive multiplexer
nor the transmit multiplexer contain any policy for handling multiple clients.\\
On the receive path, packets should be handed to the appropriate client on a first in, first out basis. However, 
in the case that a client cannot keep up with the incoming traffic and the client's received used (RxU) queue becomes full,
the multiplexer will start dropping packets. As the sDDF contains a single pool of shared buffers on the receive path,
a low priority client that cannot keep up with incoming traffic has the potential to starve a higher priority client, 
because there will be a shortage of free buffers for incoming packets. In order to prevent this, the system needs
to limit incoming throughput of lower priority clients by reducing the client's RxU queue size. The queue will 
fill up faster, and the multiplexer will drop packets earlier, which ensures a larger availability of shared buffers.\\
On the transmit path, the policy will depend on the particular use case as outlined in \autoref{s:mux_design}. Each of these
policies will need to be implemented with the design goals in mind.\\
Furthermore, the current transport layer does not track where buffers originated from. As each client has its own
pool of transmit buffers, the multiplexer needs to ensure the transmit buffer is returned to its origin after use.

\subsection{Support broadcast protocols}\label{s:arp}
The address resolution protocol (ARP) broadcasts packets to all applications in order to map a protocol
address (IPv4) with a MAC address. As the multiplexer will not know how to handle these packets/which client
to pass them on to, we could either develop a separate component to handle all broadcast traffic, or
alternatively, add the functionality to the MUX RX to duplicate these packets and forward them to all clients.
A separate component can be kept simple, as per the design goals with the aim of enabling eventual verification. It just
requires the necessary functionality extracted from an IP stack to respond to ARP. However, as ARP is based on both 
MAC address and protocol address, the ARP component would need to have a mapping of MAC address and
IPv4 address for each client. As each client could potentially alter
their IPv4 address, or change protocols altogether, this mapping would need to be done dynamically.\\ 
Alternatively, if we were to duplicate broadcast packets and forward them to all applications, the MUX RX would need to ensure
each client side receive free (RxF) queue was not empty in order to provide the MUX RX with enough free buffers to forward broadcast
packets. \\
Both designs need further evaluation to properly compare the trade-offs before we can support broadcast traffic.

\subsection{Imitate different client applications}\label{s:client}
The current implementation of the client application consists of a simple echo server. However, the client 
is limited as it expects to only ever transmit a packet after it has received one. This works for symmetric 
traffic, but does not test the system against clients with different networking demands. A webserver, for example, 
requires much higher throughput on the transmit path than the receive path. In order to mimic such a use case,
we want to design simple client applications with an event-driven model. This is because the client may need to
use more transmit buffers than are currently available in the transmit free queue. The client should then temporarily 
pause the current context while waiting for more free transmit buffers, so it is available to react to other events. 
Once more transmit free buffers are available (by which the client will be notified), the client can resume the transmit context. 
To support this, we must add continuations in the client application. This will enable us to easily imitate
different use cases with different networking demands when benchmarking.

\subsection{Add a second client to the prototype}\label{s:client2}
Adding another simple client application will be straight forward as we can re-use a lot of the code for the 
original single client application. Now there are two client applications, we want to thoroughly test the
framework to see if it performs as expected. Specifically, we want to experiment with the different 
policies developed in \autoref{s:mux_pol}, as well as different client demands. Such demands could be
symmetric traffic tested with a simple echo application as well as asymmetric traffic, tested with a client
application that either mostly receives packets but does not transmit frequently, or vice versa. Another variable
that would change the flow of the system would be experimenting with the clients' priorities. All up, we have the
following variables to experiment with:

\begin{itemize}
    \item Client priorities for scheduling. Either:
        \begin{enumerate}
            \item Client 1 runs at higher priority than client 2.
            \item Client 1 and client 2 have equal priority.
            \item Client 2 runs at higher priority than client 1.
        \end{enumerate}
    \item Client functionality. Each client could implement one of the following applications:
        \begin{enumerate}
            \item Echo application.
            \item Higher proportion of transmit. Eg. For every received packet, the client sends 100.
            \item Higher proportion of receive. Eg. For every 100 packets received, the client sends 1.
            \item Client initiated transmit. Client will transmit packets on a time out, regardless of the receive path. 
        \end{enumerate}
    \item Transmit Policy. This could be one of the following options:
        \begin{enumerate}
            \item Priority based. Client 1 takes higher priority over client 2. 
            \item Round robin. The multiplexer will alternate between responding to client 1, then client 2.
            \item Throughput based. Limit both clients' throughput to specified amounts. This could be 
            an even distribution or client 1 has a higher bandwidth limit to client 2.
        \end{enumerate}
    \item Receive flow control policy. If the clients themselves have equal priority, then this won't be necessary. 
    However, if they do not, then we can set the lower priority clients RxU queue size to a percentage of the
    higher priority client's queue size.
\end{itemize}

\subsection{Support multicore systems}\label{s:multicore}
The sDDF is implemented on top of seL4CP, which already supports multicore systems, so there are minimal changes required
to achieve this. As the transport layer is lock-free and system calls are kept to a minimum, the framework itself 
\emph{should} be capable of exploiting the parallelism of multicore hardware, by pinning components each to their 
own core. However, if there are not enough cores available, we require a policy to determine how components are distributed
across cores. For the prototype, a simple user level CPU utilisation analysis should reveal the most appropriate combinations.
This is achievable through seL4's benchmarking library.\\
Furthermore, it is possible to split the driver into two separate components. One component would be responsible for
handling client initiated events (predominantly transmit requests), while the other component would react to 
hardware events. This separation has the potential to achieve more performance on a multicore system as
each of these components could run concurrently on separate cores.\\
Additionally, concurrent execution could likely reveal bugs in the implementation or performance bottlenecks. Thorough 
analysis of results will be key in identifying this.

\subsection{Security Analysis}\label{s:security}
Component communication in the sDDF relies on shared memory and asynchronous notifications. While asynchronous communication
has considerable performance benefits (see \autoref{ch:related_work}), it means we trust each component to abide by the protocol. 
Future work, left out of scope of this thesis, will explore verifying all trusted components. However, this excludes the client
applications. We therefore must evaluate the client interfaces to ensure that a misbehaving client cannot interfere with other clients
nor any of the trusted components, including shared components such as the multiplexers. 

%\subsection{Port the sDDF to an x86 architecture with a 10Gbps NIC}\label{s:ixgbe}
%The current prototype runs on the Armv8 architecture. While this architecture is commonly used in IoT systems requiring
%high throughput networking, a significant portion
%of related work has been implemented and benchmarked on an x86 system. In particular, these systems use an ixgbe Ethernet
%driver. In keeping with our design goal of performance, having benchmarks on the same hardware as other high performance
%networking systems would allow us to better compare results.\\
%The seL4 Core Platform does not currently support x86 architectures, and nor do we have a working ixgbe driver for seL4. 
%Both of which are required for this goal.
